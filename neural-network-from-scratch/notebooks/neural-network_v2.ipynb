{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc8cef4-d674-41fa-8812-044fc577399e",
   "metadata": {},
   "source": [
    "## Neural Network v2 Implementation  22nd August 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc3481-f921-413b-a67a-7fede381150a",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a6add-54e2-47a6-881e-a8d33f09004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 17:38:45.357832: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-31 17:38:45.449949: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-31 17:38:49.301840: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-31 17:39:23.463989: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-31 17:39:23.482234: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import random_init, compute_validation_loss\n",
    "from optim.SGD import SGD\n",
    "from optim.Adam import Adam\n",
    "from optim.RMSprop import RMSprop\n",
    "from activation_func.activations import relu, cross_entropy_from_logits, sigmoid\n",
    "from keras.datasets import mnist\n",
    "from nn import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5169b-11ba-4b4e-ae6c-a665d0440cb5",
   "metadata": {},
   "source": [
    "## Training Loop MNIST Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a6802b-d95f-425c-b050-9d9137f5a901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1, Train Loss: 0.2929, Val Loss: 0.0308, Train Acc: 95.67, Val Acc: 95.74\n",
      "Epochs: 2, Train Loss: 0.1398, Val Loss: 0.0257, Train Acc: 97.11, Val Acc: 96.48\n",
      "Epochs: 3, Train Loss: 0.1039, Val Loss: 0.0268, Train Acc: 97.37, Val Acc: 96.40\n",
      "Epochs: 4, Train Loss: 0.0889, Val Loss: 0.0257, Train Acc: 97.95, Val Acc: 96.48\n",
      "Epochs: 5, Train Loss: 0.0770, Val Loss: 0.0244, Train Acc: 98.13, Val Acc: 96.83\n",
      "Epochs: 6, Train Loss: 0.0681, Val Loss: 0.0295, Train Acc: 97.99, Val Acc: 96.70\n",
      "Epochs: 7, Train Loss: 0.0568, Val Loss: 0.0248, Train Acc: 98.91, Val Acc: 97.25\n",
      "Epochs: 8, Train Loss: 0.0541, Val Loss: 0.0269, Train Acc: 98.89, Val Acc: 97.30\n",
      "Epochs: 9, Train Loss: 0.0477, Val Loss: 0.0285, Train Acc: 98.73, Val Acc: 97.22\n",
      "Epochs: 10, Train Loss: 0.0433, Val Loss: 0.0258, Train Acc: 99.19, Val Acc: 97.46\n",
      "Epochs: 11, Train Loss: 0.0416, Val Loss: 0.0303, Train Acc: 99.15, Val Acc: 97.24\n",
      "Epochs: 12, Train Loss: 0.0361, Val Loss: 0.0345, Train Acc: 98.78, Val Acc: 97.02\n",
      "Epochs: 13, Train Loss: 0.0348, Val Loss: 0.0336, Train Acc: 99.07, Val Acc: 97.23\n",
      "Epochs: 14, Train Loss: 0.0329, Val Loss: 0.0333, Train Acc: 99.26, Val Acc: 97.07\n",
      "Epochs: 15, Train Loss: 0.0276, Val Loss: 0.0314, Train Acc: 99.51, Val Acc: 97.60\n",
      "Epochs: 16, Train Loss: 0.0247, Val Loss: 0.0359, Train Acc: 99.44, Val Acc: 97.32\n",
      "Epochs: 17, Train Loss: 0.0254, Val Loss: 0.0369, Train Acc: 99.33, Val Acc: 97.30\n",
      "Epochs: 18, Train Loss: 0.0228, Val Loss: 0.0327, Train Acc: 99.42, Val Acc: 97.50\n",
      "Epochs: 19, Train Loss: 0.0241, Val Loss: 0.0325, Train Acc: 99.68, Val Acc: 97.60\n",
      "Epochs: 20, Train Loss: 0.0185, Val Loss: 0.0383, Train Acc: 99.51, Val Acc: 97.33\n",
      "Epochs: 21, Train Loss: 0.0198, Val Loss: 0.0391, Train Acc: 99.69, Val Acc: 97.52\n",
      "Epochs: 22, Train Loss: 0.0185, Val Loss: 0.0401, Train Acc: 99.66, Val Acc: 97.47\n",
      "Epochs: 23, Train Loss: 0.0226, Val Loss: 0.0400, Train Acc: 99.49, Val Acc: 97.57\n",
      "Epochs: 24, Train Loss: 0.0201, Val Loss: 0.0391, Train Acc: 99.64, Val Acc: 97.70\n",
      "Epochs: 25, Train Loss: 0.0200, Val Loss: 0.0462, Train Acc: 99.50, Val Acc: 97.32\n",
      "Epochs: 26, Train Loss: 0.0165, Val Loss: 0.0448, Train Acc: 99.73, Val Acc: 97.66\n",
      "Epochs: 27, Train Loss: 0.0193, Val Loss: 0.0454, Train Acc: 99.56, Val Acc: 97.53\n",
      "Epochs: 28, Train Loss: 0.0199, Val Loss: 0.0480, Train Acc: 99.29, Val Acc: 97.31\n",
      "Epochs: 29, Train Loss: 0.0144, Val Loss: 0.0478, Train Acc: 99.37, Val Acc: 97.09\n",
      "Epochs: 30, Train Loss: 0.0166, Val Loss: 0.0451, Train Acc: 99.78, Val Acc: 97.78\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Making a validation set\n",
    "X_val = X_train[-10240:,]\n",
    "y_val = y_train[-10240:]\n",
    "\n",
    "X_train = X_train[:-10240]\n",
    "y_train = y_train[:-10240]\n",
    "\n",
    "# Normalize and reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Parameters\n",
    "layers_dim = [784, 128, 64, 10]\n",
    "\n",
    "# Random initialization of parameters\n",
    "params = random_init(layers_dim)\n",
    "model = nn(params)\n",
    "\n",
    "# Mini batch\n",
    "batch_size = 64\n",
    "m = X_train.shape[0]\n",
    "m_val = X_val.shape[0]\n",
    "\n",
    "num_indices = m // batch_size\n",
    "num_indices_val = m_val // batch_size\n",
    "\n",
    "epochs = 30\n",
    "lr = 1e-2\n",
    "optimizer = RMSprop(params, lr)\n",
    "activations = [relu, relu, relu, relu, relu]\n",
    "\n",
    "# best config 1e-2 15epoch adam 64bs 99.6%\n",
    "# 2nd best config 1e-2 15 epoch rmsprop 64bs 99.88%\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle on each epoch\n",
    "    perm = np.random.permutation(m)\n",
    "    X_shuffled = X_train[perm, :]\n",
    "    y_shuffled = y_train[perm,]\n",
    "\n",
    "    perm_val = np.random.permutation(m_val)\n",
    "    X_val_shuffled = X_val[perm_val, :]\n",
    "    y_val_shuffled = y_val[perm_val,]\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_val = 0.0 \n",
    "\n",
    "    # Training Loop\n",
    "    for i in range(num_indices):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X_shuffled[start:end, :]\n",
    "        y_batch = y_shuffled[start:end,]\n",
    "\n",
    "        # Forward pass\n",
    "        Z, cache = model.forward(X_batch, activations)\n",
    "\n",
    "        # Compute loss\n",
    "        loss, dZ3 = cross_entropy_from_logits(Z, y_batch)\n",
    "        \n",
    "        # sum over samples\n",
    "        epoch_loss += loss * X_batch.shape[0]  \n",
    "        \n",
    "        # Backward pass\n",
    "        gradients = model.backward(y_batch, dZ3, cache, activations)\n",
    " \n",
    "        # Update weights \n",
    "        params = optimizer.step(gradients)\n",
    "        \n",
    "    # Validation Loop\n",
    "    for i in range(num_indices_val):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size \n",
    "\n",
    "        X_val_batch = X_val_shuffled[start:end, :]\n",
    "        y_val_batch = y_val_shuffled[start:end,]\n",
    "\n",
    "        val_loss = compute_validation_loss(model, X_val_batch, y_val_batch, activations, batch_norm = False)\n",
    "        epoch_loss_val += val_loss * X_val_batch.shape[0]\n",
    "        \n",
    "    epoch_loss /= m\n",
    "    epoch_loss_val /= m\n",
    "    train_acc = model.accuracy(X_train, y_train, activations, batch_norm = False)\n",
    "    val_acc = model.accuracy(X_val, y_val, activations, batch_norm = False)\n",
    "    \n",
    "    print(f\"Epochs: {epoch+1}, Train Loss: {epoch_loss:.4f}, Val Loss: {epoch_loss_val:.4f}, Train Acc: {train_acc * 100:.2f}, Val Acc: {val_acc * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202276d0-d150-4dd4-85a1-bf9b30eef115",
   "metadata": {},
   "source": [
    "## Test/Train Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4621fefb-d227-442c-b05f-0fd360a01e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.60%\n",
      "Train Accuracy: 99.78%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate \n",
    "test_acc = model.accuracy(X_test, y_test, activations, batch_norm = False)\n",
    "train_acc = model.accuracy(X_train, y_train, activations, batch_norm = False)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "print(f\"Train Accuracy: {train_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077df8ba-a48e-4687-be7b-db9751441788",
   "metadata": {},
   "source": [
    "## Checking Model in Action with Images/logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d89def-efa9-4f8a-8655-71d3a4e7a4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [ -9.683  28.664  -3.102   2.867   1.532 -10.072  -1.563  11.176   3.618\n",
      "  -3.897]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [ 28.285 -23.67   -5.476 -12.671   1.285 -15.586  -2.921  -6.9    -9.404\n",
      "   1.035]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [-14.961 -11.243  22.201  -0.237   6.038   3.083  -7.44  -19.015 -21.275\n",
      "   4.716]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [ 21.936 -19.275  -6.881 -12.412  -2.806 -11.533  -3.355  -6.673 -11.817\n",
      "  -2.652]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_single(X, params, model, acts):\n",
    "    # forward returns (output, cache)\n",
    "    probs, _ = model.forward(X[np.newaxis, :], acts)  \n",
    "    y_pred = np.argmax(probs, axis=1)[0]   # axis=1 because batch dimension is first\n",
    "    return y_pred, probs[0]\n",
    "\n",
    "for i in range(1,5):\n",
    "    idx = np.random.randint(0, X_test.shape[0])\n",
    "    x_example = X_test[idx]\n",
    "    y_true = y_test[idx]\n",
    "    \n",
    "    # Predict\n",
    "    y_pred, probs = predict_single(x_example, params, model, activations)\n",
    "    \n",
    "    # Reshape and plot image (assuming 28x28)\n",
    "    plt.imshow(x_example.reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"True: {y_true} | Predicted: {y_pred}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Probabilities:\", np.round(probs, 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6068145-2f08-40e6-a06e-682acec078cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1, Train Loss: 0.3103, Val Loss: 0.0026, Train Acc: 95.08, Val Acc: 95.07\n",
      "Epochs: 2, Train Loss: 0.1677, Val Loss: 0.0023, Train Acc: 96.40, Val Acc: 95.78\n",
      "Epochs: 3, Train Loss: 0.1400, Val Loss: 0.0019, Train Acc: 97.32, Val Acc: 96.40\n",
      "Epochs: 4, Train Loss: 0.1227, Val Loss: 0.0019, Train Acc: 97.50, Val Acc: 96.48\n",
      "Epochs: 5, Train Loss: 0.1128, Val Loss: 0.0018, Train Acc: 97.64, Val Acc: 96.60\n",
      "Epochs: 6, Train Loss: 0.1051, Val Loss: 0.0017, Train Acc: 97.99, Val Acc: 96.92\n",
      "Epochs: 7, Train Loss: 0.0982, Val Loss: 0.0018, Train Acc: 98.00, Val Acc: 96.75\n",
      "Epochs: 8, Train Loss: 0.0907, Val Loss: 0.0016, Train Acc: 98.33, Val Acc: 97.17\n",
      "Epochs: 9, Train Loss: 0.0893, Val Loss: 0.0017, Train Acc: 98.38, Val Acc: 97.01\n",
      "Epochs: 10, Train Loss: 0.0851, Val Loss: 0.0018, Train Acc: 98.32, Val Acc: 96.76\n",
      "Epochs: 11, Train Loss: 0.0804, Val Loss: 0.0016, Train Acc: 98.57, Val Acc: 97.08\n",
      "Epochs: 12, Train Loss: 0.0762, Val Loss: 0.0016, Train Acc: 98.71, Val Acc: 97.26\n",
      "Epochs: 13, Train Loss: 0.0751, Val Loss: 0.0017, Train Acc: 98.77, Val Acc: 96.99\n",
      "Epochs: 14, Train Loss: 0.0734, Val Loss: 0.0017, Train Acc: 98.93, Val Acc: 97.26\n",
      "Epochs: 15, Train Loss: 0.0718, Val Loss: 0.0018, Train Acc: 98.75, Val Acc: 96.82\n",
      "Epochs: 16, Train Loss: 0.0687, Val Loss: 0.0017, Train Acc: 98.94, Val Acc: 97.10\n",
      "Epochs: 17, Train Loss: 0.0634, Val Loss: 0.0018, Train Acc: 98.95, Val Acc: 97.02\n",
      "Epochs: 18, Train Loss: 0.0661, Val Loss: 0.0017, Train Acc: 99.10, Val Acc: 97.20\n",
      "Epochs: 19, Train Loss: 0.0628, Val Loss: 0.0018, Train Acc: 99.07, Val Acc: 97.02\n",
      "Epochs: 20, Train Loss: 0.0615, Val Loss: 0.0019, Train Acc: 99.09, Val Acc: 96.90\n",
      "Epochs: 21, Train Loss: 0.0581, Val Loss: 0.0019, Train Acc: 98.99, Val Acc: 97.04\n",
      "Epochs: 22, Train Loss: 0.0607, Val Loss: 0.0020, Train Acc: 99.01, Val Acc: 96.77\n",
      "Epochs: 23, Train Loss: 0.0590, Val Loss: 0.0018, Train Acc: 99.08, Val Acc: 97.20\n",
      "Epochs: 24, Train Loss: 0.0563, Val Loss: 0.0018, Train Acc: 99.17, Val Acc: 97.15\n",
      "Epochs: 25, Train Loss: 0.0546, Val Loss: 0.0020, Train Acc: 99.07, Val Acc: 96.81\n",
      "Epochs: 26, Train Loss: 0.0516, Val Loss: 0.0019, Train Acc: 99.20, Val Acc: 96.95\n",
      "Epochs: 27, Train Loss: 0.0523, Val Loss: 0.0020, Train Acc: 99.23, Val Acc: 96.98\n",
      "Epochs: 28, Train Loss: 0.0530, Val Loss: 0.0020, Train Acc: 99.02, Val Acc: 96.71\n",
      "Epochs: 29, Train Loss: 0.0498, Val Loss: 0.0020, Train Acc: 99.26, Val Acc: 96.87\n",
      "Epochs: 30, Train Loss: 0.0511, Val Loss: 0.0019, Train Acc: 99.33, Val Acc: 97.04\n",
      "CPU times: user 2min 39s, sys: 1.6 s, total: 2min 40s\n",
      "Wall time: 47.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "from utils import random_init, compute_validation_loss\n",
    "from optim.SGD import SGD\n",
    "from optim.Adam import Adam\n",
    "from optim.RMSprop import RMSprop\n",
    "from activation_func.activations import relu, cross_entropy_from_logits\n",
    "from keras.datasets import mnist\n",
    "from nn import nn\n",
    "\n",
    "# Load and preprocess data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Making a validation set\n",
    "X_val = X_train[-10240:,]\n",
    "y_val = y_train[-10240:]\n",
    "\n",
    "X_train = X_train[:-10240]\n",
    "y_train = y_train[:-10240]\n",
    "\n",
    "# Normalize and reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Parameters\n",
    "layers_dim = [784, 32, 16, 10]\n",
    "\n",
    "# Random initialization of parameters\n",
    "params = random_init(layers_dim, batch_norm = True)\n",
    "\n",
    "model = nn(params) \n",
    "activations = [relu, relu, relu, relu]\n",
    "# Mini batch\n",
    "batch_size = 64\n",
    "\n",
    "m = X_train.shape[0]\n",
    "m_val = X_val.shape[0]\n",
    "\n",
    "num_indices = m // batch_size\n",
    "num_indices_val = m_val // batch_size\n",
    "epochs = 30\n",
    "lr = 1e-2\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(params, lr, batch_norm = True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle on each epoch\n",
    "    perm = np.random.permutation(m)\n",
    "    X_shuffled = X_train[perm, :]\n",
    "    y_shuffled = y_train[perm,]\n",
    "    \n",
    "    perm_val = np.random.permutation(m_val)\n",
    "    X_val_shuffled = X_val[perm_val, :]\n",
    "    y_val_shuffled = y_val[perm_val,]\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_val = 0.0\n",
    "    # Training Loop\n",
    "    for i in range(num_indices):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X_shuffled[start:end, :]\n",
    "        y_batch = y_shuffled[start:end,]\n",
    "        \n",
    "        # Forward pass\n",
    "        Z, cache = model.forward(X = X_batch, activations = activations, batch_norm = True, verbose = False)\n",
    "\n",
    "        # Compute loss\n",
    "        train_loss, dZ3 = cross_entropy_from_logits(Z, y_batch)\n",
    "        \n",
    "        # train loss\n",
    "        epoch_loss += train_loss * X_batch.shape[0]\n",
    "        \n",
    "        # Backward pass\n",
    "        gradients = model.backward(y_batch, dZ3, cache, activations, batch_norm = True)\n",
    " \n",
    "        # Update weights\n",
    "        params = optimizer.step(gradients)\n",
    "    # Validation loop\n",
    "    for i in range(num_indices_val):\n",
    "        start = i * batch_size\n",
    "        end =  start + batch_size\n",
    "        X_val_batch = X_val_shuffled[start:end, :]\n",
    "        y_val_batch = y_val_shuffled[start:end,]\n",
    "\n",
    "        # val loss\n",
    "        val_loss = compute_validation_loss(model, X_val_batch, y_val_batch, activations, batch_norm = True)\n",
    "        epoch_loss_val += val_loss \n",
    "        \n",
    "    epoch_loss /= m\n",
    "    epoch_loss_val /= m_val\n",
    "    \n",
    "    train_acc = model.accuracy(X_train, y_train, activations, batch_norm = True)\n",
    "    val_acc = model.accuracy(X_val, y_val, activations, batch_norm = True)\n",
    "    print(f\"Epochs: {epoch+1}, Train Loss: {epoch_loss:.4f}, Val Loss: {epoch_loss_val:.4f}, Train Acc: {train_acc * 100:.2f}, Val Acc: {val_acc * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d9fd76d-1fbe-4ea5-9ae3-5673b2134545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2504 - val_accuracy: 0.9547 - val_loss: 0.1602\n",
      "Epoch 2/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1476 - val_accuracy: 0.9539 - val_loss: 0.1843\n",
      "Epoch 3/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.1229 - val_accuracy: 0.9480 - val_loss: 0.2129\n",
      "Epoch 4/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.1196 - val_accuracy: 0.9665 - val_loss: 0.1470\n",
      "Epoch 5/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0997 - val_accuracy: 0.9655 - val_loss: 0.1573\n",
      "Epoch 6/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0925 - val_accuracy: 0.9647 - val_loss: 0.1790\n",
      "Epoch 7/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.0903 - val_accuracy: 0.9619 - val_loss: 0.1924\n",
      "Epoch 8/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0972 - val_accuracy: 0.9672 - val_loss: 0.1563\n",
      "Epoch 9/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0758 - val_accuracy: 0.9652 - val_loss: 0.1944\n",
      "Epoch 10/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0774 - val_accuracy: 0.9657 - val_loss: 0.1715\n",
      "Epoch 11/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0730 - val_accuracy: 0.9625 - val_loss: 0.2131\n",
      "Epoch 12/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0742 - val_accuracy: 0.9660 - val_loss: 0.2023\n",
      "Epoch 13/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0724 - val_accuracy: 0.9662 - val_loss: 0.1920\n",
      "Epoch 14/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0699 - val_accuracy: 0.9702 - val_loss: 0.1657\n",
      "Epoch 15/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0596 - val_accuracy: 0.9687 - val_loss: 0.1939\n",
      "Epoch 16/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0652 - val_accuracy: 0.9683 - val_loss: 0.2090\n",
      "Epoch 17/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0657 - val_accuracy: 0.9699 - val_loss: 0.1927\n",
      "Epoch 18/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0516 - val_accuracy: 0.9657 - val_loss: 0.2425\n",
      "Epoch 19/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0563 - val_accuracy: 0.9696 - val_loss: 0.1931\n",
      "Epoch 20/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0556 - val_accuracy: 0.9680 - val_loss: 0.2258\n",
      "Epoch 21/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0535 - val_accuracy: 0.9689 - val_loss: 0.2030\n",
      "Epoch 22/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0594 - val_accuracy: 0.9685 - val_loss: 0.2193\n",
      "Epoch 23/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0544 - val_accuracy: 0.9710 - val_loss: 0.2372\n",
      "Epoch 24/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0480 - val_accuracy: 0.9693 - val_loss: 0.2058\n",
      "Epoch 25/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0473 - val_accuracy: 0.9682 - val_loss: 0.2059\n",
      "Epoch 26/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0549 - val_accuracy: 0.9681 - val_loss: 0.2444\n",
      "Epoch 27/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0455 - val_accuracy: 0.9693 - val_loss: 0.2274\n",
      "Epoch 28/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0552 - val_accuracy: 0.9723 - val_loss: 0.2252\n",
      "Epoch 29/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0536 - val_accuracy: 0.9721 - val_loss: 0.2357\n",
      "Epoch 30/30\n",
      "\u001b[1m778/778\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0603 - val_accuracy: 0.9668 - val_loss: 0.2491\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load and preprocess data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Define the model architecture using Sequential API\n",
    "layers_dim = [784, 128, 64, 10]\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28))) # Flattens the 28x28 image into a 784-element vector\n",
    "\n",
    "# Add hidden layers with Batch Normalization and ReLU activation\n",
    "for i in range(1, len(layers_dim) - 1):\n",
    "    model.add(Dense(layers_dim[i]))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "# Add the final output layer\n",
    "model.add(Dense(layers_dim[-1]))\n",
    "\n",
    "# Compile the model with the specified optimizer and loss\n",
    "lr = 1e-2\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model, using a validation split to mimic the original code's validation set\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=epochs,\n",
    "    validation_split=10240/60000, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491dd3a-8900-4985-8b05-63833e444097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn4",
   "language": "python",
   "name": "neural-network-from-scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
